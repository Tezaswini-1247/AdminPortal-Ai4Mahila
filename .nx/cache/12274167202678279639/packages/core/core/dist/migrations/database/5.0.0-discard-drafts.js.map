{"version":3,"file":"5.0.0-discard-drafts.js","sources":["../../../src/migrations/database/5.0.0-discard-drafts.ts"],"sourcesContent":["/**\r\n * This migration is responsible for creating the draft counterpart for all the entries that were in a published state.\r\n *\r\n * In v4, entries could either be in a draft or published state, but not both at the same time.\r\n * In v5, we introduced the concept of document, and an entry can be in a draft or published state.\r\n *\r\n * This means the migration needs to create the draft counterpart if an entry was published.\r\n *\r\n * This migration performs the following steps:\r\n * 1. Creates draft entries for all published entries, without it's components, dynamic zones or relations.\r\n * 2. Using the document service, discard those same drafts to copy its relations.\r\n */\r\n\r\n/* eslint-disable no-continue */\r\nimport type { UID } from '@strapi/types';\r\nimport type { Database, Migration } from '@strapi/database';\r\nimport { async, contentTypes } from '@strapi/utils';\r\nimport { createDocumentService } from '../../services/document-service';\r\n\r\ntype DocumentVersion = { documentId: string; locale: string };\r\ntype Knex = Parameters<Migration['up']>[0];\r\n\r\n/**\r\n * Check if the model has draft and publish enabled.\r\n */\r\nconst hasDraftAndPublish = async (trx: Knex, meta: any) => {\r\n  const hasTable = await trx.schema.hasTable(meta.tableName);\r\n\r\n  if (!hasTable) {\r\n    return false;\r\n  }\r\n\r\n  const uid = meta.uid as UID.ContentType;\r\n  const model = strapi.getModel(uid);\r\n  const hasDP = contentTypes.hasDraftAndPublish(model);\r\n  if (!hasDP) {\r\n    return false;\r\n  }\r\n\r\n  return true;\r\n};\r\n\r\n/**\r\n * Copy all the published entries to draft entries, without it's components, dynamic zones or relations.\r\n * This ensures all necessary draft's exist before copying it's relations.\r\n */\r\nasync function copyPublishedEntriesToDraft({\r\n  db,\r\n  trx,\r\n  uid,\r\n}: {\r\n  db: Database;\r\n  trx: Knex;\r\n  uid: string;\r\n}) {\r\n  // Extract all scalar attributes to use in the insert query\r\n  const meta = db.metadata.get(uid);\r\n\r\n  // Get scalar attributes that will be copied over the new draft\r\n  const scalarAttributes = Object.values(meta.attributes).reduce((acc, attribute: any) => {\r\n    if (['id'].includes(attribute.columnName)) {\r\n      return acc;\r\n    }\r\n\r\n    if (contentTypes.isScalarAttribute(attribute)) {\r\n      acc.push(attribute.columnName);\r\n    }\r\n\r\n    return acc;\r\n  }, [] as string[]);\r\n\r\n  /**\r\n   * Query to copy the published entries into draft entries.\r\n   *\r\n   * INSERT INTO tableName (columnName1, columnName2, columnName3, ...)\r\n   * SELECT columnName1, columnName2, columnName3, ...\r\n   * FROM tableName\r\n   */\r\n  await trx\r\n    // INSERT INTO tableName (columnName1, columnName2, columnName3, ...)\r\n    .into(\r\n      trx.raw(`?? (${scalarAttributes.map(() => `??`).join(', ')})`, [\r\n        meta.tableName,\r\n        ...scalarAttributes,\r\n      ])\r\n    )\r\n    .insert((subQb: typeof trx) => {\r\n      // SELECT columnName1, columnName2, columnName3, ...\r\n      subQb\r\n        .select(\r\n          ...scalarAttributes.map((att: string) => {\r\n            // Override 'publishedAt' and 'updatedAt' attributes\r\n            if (att === 'published_at') {\r\n              return trx.raw('NULL as ??', 'published_at');\r\n            }\r\n\r\n            return att;\r\n          })\r\n        )\r\n        .from(meta.tableName)\r\n        // Only select entries that were published\r\n        .whereNotNull('published_at');\r\n    });\r\n}\r\n\r\n/**\r\n * Load a batch of versions to discard.\r\n *\r\n * Versions with only a draft version will be ignored.\r\n * Only versions with a published version (which always have a draft version) will be discarded.\r\n */\r\nexport async function* getBatchToDiscard({\r\n  db,\r\n  trx,\r\n  uid,\r\n  batchSize = 1000,\r\n}: {\r\n  db: Database;\r\n  trx: Knex;\r\n  uid: string;\r\n  batchSize?: number;\r\n}) {\r\n  let offset = 0;\r\n  let hasMore = true;\r\n\r\n  while (hasMore) {\r\n    // Look for the published entries to discard\r\n    const batch: DocumentVersion[] = await db\r\n      .queryBuilder(uid)\r\n      .select(['id', 'documentId', 'locale'])\r\n      .where({ publishedAt: { $ne: null } })\r\n      .limit(batchSize)\r\n      .offset(offset)\r\n      .orderBy('id')\r\n      .transacting(trx)\r\n      .execute();\r\n\r\n    if (batch.length < batchSize) {\r\n      hasMore = false;\r\n    }\r\n\r\n    offset += batchSize;\r\n    yield batch;\r\n  }\r\n}\r\n\r\n/**\r\n * 2 pass migration to create the draft entries for all the published entries.\r\n * And then discard the drafts to copy the relations.\r\n */\r\nconst migrateUp = async (trx: Knex, db: Database) => {\r\n  const dpModels = [];\r\n  for (const meta of db.metadata.values()) {\r\n    const hasDP = await hasDraftAndPublish(trx, meta);\r\n    if (hasDP) {\r\n      dpModels.push(meta);\r\n    }\r\n  }\r\n\r\n  /**\r\n   * Create plain draft entries for all the entries that were published.\r\n   */\r\n  for (const model of dpModels) {\r\n    await copyPublishedEntriesToDraft({ db, trx, uid: model.uid });\r\n  }\r\n\r\n  /**\r\n   * Discard the drafts will copy the relations from the published entries to the newly created drafts.\r\n   *\r\n   * Load a batch of entries (batched to prevent loading millions of rows at once ),\r\n   * and discard them using the document service.\r\n   *\r\n   * NOTE: This is using a custom document service without any validations,\r\n   *       to prevent the migration from failing if users already had invalid data in V4.\r\n   *       E.g. @see https://github.com/strapi/strapi/issues/21583\r\n   */\r\n  const documentService = createDocumentService(strapi, {\r\n    async validateEntityCreation(_, data) {\r\n      return data;\r\n    },\r\n    async validateEntityUpdate(_, data) {\r\n      // Data can be partially empty on partial updates\r\n      // This migration doesn't trigger any update (or partial update),\r\n      // so it's safe to return the data as is.\r\n      return data as any;\r\n    },\r\n  });\r\n\r\n  for (const model of dpModels) {\r\n    const discardDraft = async (entry: DocumentVersion) =>\r\n      documentService(model.uid as UID.ContentType).discardDraft({\r\n        documentId: entry.documentId,\r\n        locale: entry.locale,\r\n      });\r\n\r\n    for await (const batch of getBatchToDiscard({ db, trx, uid: model.uid })) {\r\n      // NOTE: concurrency had to be disabled to prevent a race condition with self-references\r\n      // TODO: improve performance in a safe way\r\n      await async.map(batch, discardDraft, { concurrency: 1 });\r\n    }\r\n  }\r\n};\r\n\r\nexport const discardDocumentDrafts: Migration = {\r\n  name: 'core::5.0.0-discard-drafts',\r\n  async up(trx, db) {\r\n    await migrateUp(trx, db);\r\n  },\r\n  async down() {\r\n    throw new Error('not implemented');\r\n  },\r\n};\r\n"],"names":["contentTypes","createDocumentService","async"],"mappings":";;;;AAyBA,MAAM,qBAAqB,OAAO,KAAW,SAAc;AACzD,QAAM,WAAW,MAAM,IAAI,OAAO,SAAS,KAAK,SAAS;AAEzD,MAAI,CAAC,UAAU;AACN,WAAA;AAAA,EAAA;AAGT,QAAM,MAAM,KAAK;AACX,QAAA,QAAQ,OAAO,SAAS,GAAG;AAC3B,QAAA,QAAQA,YAAAA,aAAa,mBAAmB,KAAK;AACnD,MAAI,CAAC,OAAO;AACH,WAAA;AAAA,EAAA;AAGF,SAAA;AACT;AAMA,eAAe,4BAA4B;AAAA,EACzC;AAAA,EACA;AAAA,EACA;AACF,GAIG;AAED,QAAM,OAAO,GAAG,SAAS,IAAI,GAAG;AAG1B,QAAA,mBAAmB,OAAO,OAAO,KAAK,UAAU,EAAE,OAAO,CAAC,KAAK,cAAmB;AACtF,QAAI,CAAC,IAAI,EAAE,SAAS,UAAU,UAAU,GAAG;AAClC,aAAA;AAAA,IAAA;AAGL,QAAAA,YAAA,aAAa,kBAAkB,SAAS,GAAG;AACzC,UAAA,KAAK,UAAU,UAAU;AAAA,IAAA;AAGxB,WAAA;AAAA,EACT,GAAG,EAAc;AASjB,QAAM,IAEH;AAAA,IACC,IAAI,IAAI,OAAO,iBAAiB,IAAI,MAAM,IAAI,EAAE,KAAK,IAAI,CAAC,KAAK;AAAA,MAC7D,KAAK;AAAA,MACL,GAAG;AAAA,IACJ,CAAA;AAAA,EAAA,EAEF,OAAO,CAAC,UAAsB;AAG1B,UAAA;AAAA,MACC,GAAG,iBAAiB,IAAI,CAAC,QAAgB;AAEvC,YAAI,QAAQ,gBAAgB;AACnB,iBAAA,IAAI,IAAI,cAAc,cAAc;AAAA,QAAA;AAGtC,eAAA;AAAA,MACR,CAAA;AAAA,MAEF,KAAK,KAAK,SAAS,EAEnB,aAAa,cAAc;AAAA,EAAA,CAC/B;AACL;AAQA,gBAAuB,kBAAkB;AAAA,EACvC;AAAA,EACA;AAAA,EACA;AAAA,EACA,YAAY;AACd,GAKG;AACD,MAAI,SAAS;AACb,MAAI,UAAU;AAEd,SAAO,SAAS;AAEd,UAAM,QAA2B,MAAM,GACpC,aAAa,GAAG,EAChB,OAAO,CAAC,MAAM,cAAc,QAAQ,CAAC,EACrC,MAAM,EAAE,aAAa,EAAE,KAAK,KAAO,EAAA,CAAC,EACpC,MAAM,SAAS,EACf,OAAO,MAAM,EACb,QAAQ,IAAI,EACZ,YAAY,GAAG,EACf,QAAQ;AAEP,QAAA,MAAM,SAAS,WAAW;AAClB,gBAAA;AAAA,IAAA;AAGF,cAAA;AACJ,UAAA;AAAA,EAAA;AAEV;AAMA,MAAM,YAAY,OAAO,KAAW,OAAiB;AACnD,QAAM,WAAW,CAAC;AAClB,aAAW,QAAQ,GAAG,SAAS,OAAA,GAAU;AACvC,UAAM,QAAQ,MAAM,mBAAmB,KAAK,IAAI;AAChD,QAAI,OAAO;AACT,eAAS,KAAK,IAAI;AAAA,IAAA;AAAA,EACpB;AAMF,aAAW,SAAS,UAAU;AAC5B,UAAM,4BAA4B,EAAE,IAAI,KAAK,KAAK,MAAM,KAAK;AAAA,EAAA;AAazD,QAAA,kBAAkBC,4BAAsB,QAAQ;AAAA,IACpD,MAAM,uBAAuB,GAAG,MAAM;AAC7B,aAAA;AAAA,IACT;AAAA,IACA,MAAM,qBAAqB,GAAG,MAAM;AAI3B,aAAA;AAAA,IAAA;AAAA,EACT,CACD;AAED,aAAW,SAAS,UAAU;AAC5B,UAAM,eAAe,OAAO,UAC1B,gBAAgB,MAAM,GAAsB,EAAE,aAAa;AAAA,MACzD,YAAY,MAAM;AAAA,MAClB,QAAQ,MAAM;AAAA,IAAA,CACf;AAEc,qBAAA,SAAS,kBAAkB,EAAE,IAAI,KAAK,KAAK,MAAM,IAAI,CAAC,GAAG;AAGxE,YAAMC,YAAAA,MAAM,IAAI,OAAO,cAAc,EAAE,aAAa,GAAG;AAAA,IAAA;AAAA,EACzD;AAEJ;AAEO,MAAM,wBAAmC;AAAA,EAC9C,MAAM;AAAA,EACN,MAAM,GAAG,KAAK,IAAI;AACV,UAAA,UAAU,KAAK,EAAE;AAAA,EACzB;AAAA,EACA,MAAM,OAAO;AACL,UAAA,IAAI,MAAM,iBAAiB;AAAA,EAAA;AAErC;;;"}